\section{An abstract notion of files: requests}
The request is an abstract notion of file which can be conveniently used for defining powerful sources. A request can denote a local file, a remote file, or even a dynamically generated file. They are resolved to a local file thanks to a set of \emph{protocols}. Then, audio requests are transparently decoded thanks to a set of audio and metadata \emph{formats}.

The systematic use of requests to access files allows you to use remote URIs instead of local paths everywhere. It is perfectly OK to create a playlist for a remote list containing remote URIs: \begin{verbatim}
playlist("http://my/friends/playlist.pls")
\end{verbatim}
.

\subsection{The resolution process}
The nice thing about resolution is that it is recursive and supports backtracking. An URI can be changed into a list of new ones, which are in turn resolved. The process succeeds if some valid local file appears at some point. If it doesn't succeed on one branch then it goes back to another branch. A typical complex resolution would be:

\begin{itemize}
\item \verb+bubble:artist="bodom"+\begin{itemize}
\item \verb+ftp://no/where+\begin{itemize}
\item \verb+Error+

\end{itemize}

\item \verb+ftp://some/valid.ogg+\begin{itemize}
\item \verb+/tmp/success.ogg+

\end{itemize}


\end{itemize}


\end{itemize}
On top of that, metadata is extracted at every step in the branch. Usually, only the final local file yields interesting metadata (artist,album,...). But metadata can also be the nickname of the user who requested the song, set using the \verb+annotate+ protocol.

At the end of the resolution process, in case of a media request,
liquidsoap checks that the file is decodable,
\emph{i.e.}, there should be a valid decoder for it.

Each request gets assigned a request identifier (RID) which is used by
various sources to identify which request(s) they are using. Knowing
this number, you can monitor a request, even after it's been destroyed
(see setting \verb+request.grace_time+). Two \href{server.html}{server}
commands are available: \verb+request.trace+ shows a log of
the resolution process and \verb+request.metadata+ shows the
current request metadata. In addition, server commands are available
to obtain the list of all requests, alive requests, currently resolving
requests and currently playing requests (respectively
\verb+request.all+,
\verb+request.alive+,
\verb+request.resolving+,
\verb+request.on_air+).

\subsection{Currently supported protocols}
\begin{itemize}
\item SMB, FTP and HTTP using ufetch (provided by our ocaml-fetch distribution)
\item HTTP, HTTPS, FTP thanks to wget
\item SAY for speech synthesis (requires festival): \verb+say:I am a robot+ resolves to the WAV file resulting from the synthesis.
\item TIME for speech synthesis of the current time: \begin{verbatim}
time: It is exactly $(time), and you're still listening.
\end{verbatim}

\item ANNOTATE for manually setting metadata, typically used in \begin{verbatim}
annotate:nick="alice",message="for bob":/some/track/uri
\end{verbatim}


\end{itemize}
The extra metadata can then be synthesized in the audio stream, or merged into the standard metadata fields, or used on a rich web interface...
It is also possible to add a new protocol from the script, as it is done with \href{bubble.html}{bubble} for getting songs from a database query.

\subsection{Currently supported formats}
\begin{itemize}
\item MPEG-1 Layer II (MP2) and Layer III (MP3) through libmad and \verb+ocaml-mad+
\item Ogg Vorbis through libvorbis and \verb+ocaml-vorbis+
\item WAV
\item AAC
\item and much more through external decoders!

\end{itemize}
